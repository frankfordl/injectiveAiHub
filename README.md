# InjectiveAiHub - åŸºäºInjectiveçš„å»ä¸­å¿ƒåŒ–AIåä½œå¹³å°

<div align="center">
<img src="https://img.shields.io/badge/Solidity-363636?style=for-the-badge&logo=solidity&logoColor=white" alt="Solidity" />
<img src="https://img.shields.io/badge/Foundry-000000?style=for-the-badge&logo=foundry&logoColor=white" alt="Foundry" />
<img src="https://img.shields.io/badge/Injective-000000?style=for-the-badge&logo=injective&logoColor=white" alt="Injective" />
<img src="https://img.shields.io/badge/TypeScript-007ACC?style=for-the-badge&logo=typescript&logoColor=white" alt="TypeScript" />
<img src="https://img.shields.io/badge/Next.js-000000?style=for-the-badge&logo=nextdotjs&logoColor=white" alt="Next.js" />
<img src="https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white" alt="Python" />
<img src="https://img.shields.io/badge/LLaMA-FF6B6B?style=for-the-badge&logo=meta&logoColor=white" alt="LLaMA" />
</div>

## ğŸ—ï¸ é¡¹ç›®æ¦‚è¿°

InjectiveAiHubæ˜¯ä¸€ä¸ªåŸºäºInjectiveåŒºå—é“¾çš„å»ä¸­å¿ƒåŒ–AIåä½œè®­ç»ƒå¹³å°ï¼Œé€šè¿‡æ™ºèƒ½åˆçº¦å®ç°é€æ˜ã€å…¬å¹³çš„åˆ†å¸ƒå¼æœºå™¨å­¦ä¹ ç”Ÿæ€ç³»ç»Ÿã€‚å¹³å°ä½¿ç”¨åŸç”ŸINJä»£å¸ä½œä¸ºè´¨æŠ¼å’Œå¥–åŠ±æœºåˆ¶ï¼Œç¡®ä¿ç½‘ç»œå®‰å…¨å’Œå‚ä¸è€…æ¿€åŠ±ã€‚

### ğŸ¯ æ ¸å¿ƒç‰¹æ€§

- ğŸ”— **å®Œå…¨å»ä¸­å¿ƒåŒ–**: åŸºäºInjectiveæ™ºèƒ½åˆçº¦çš„æ— ä¿¡ä»»åä½œ
- ğŸ’ **åŸç”ŸINJè´¨æŠ¼**: ä½¿ç”¨InjectiveåŸç”Ÿä»£å¸è¿›è¡Œè´¨æŠ¼å’Œå¥–åŠ±
- ğŸ¤– **åˆ†å¸ƒå¼AIè®­ç»ƒ**: å¤šæ–¹åä½œçš„è”é‚¦å­¦ä¹ æ¶æ„
- ğŸ›¡ï¸ **å®‰å…¨ä¿éšœ**: æ™ºèƒ½åˆçº¦é©±åŠ¨çš„è´¨æŠ¼å’Œæƒ©ç½šæœºåˆ¶
- ğŸ“Š **é€æ˜æ²»ç†**: é“¾ä¸ŠæŠ•ç¥¨å’Œç¤¾åŒºå†³ç­–
- ğŸ” **éšç§ä¿æŠ¤**: è”é‚¦å­¦ä¹ ä¿æŠ¤æ•°æ®éšç§
- ğŸ¦™ **LLaMA 2 7Bè®­ç»ƒ**: é›†æˆå¤§è¯­è¨€æ¨¡å‹åˆ†å¸ƒå¼è®­ç»ƒ

## ğŸ“ é¡¹ç›®ç»“æ„

```
<File can be used for the pnpm dev command and the LLamacore module.>
injectiveAiHub/
â”œâ”€â”€ apps/
â”‚   â”œâ”€â”€ frontend/          # Next.jså‰ç«¯åº”ç”¨
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ public/
â”‚   â”‚   â”œâ”€â”€ package.json
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ inj_t/            # Foundryæ™ºèƒ½åˆçº¦é¡¹ç›®
â”‚       â”œâ”€â”€ src/          # æ™ºèƒ½åˆçº¦æºç 
â”‚       â”œâ”€â”€ test/         # åˆçº¦æµ‹è¯•
â”‚       â”œâ”€â”€ script/       # éƒ¨ç½²è„šæœ¬
â”‚       â””â”€â”€ foundry.toml
â””â”€â”€ llamacore/            # LLaMA 2 7Båˆ†å¸ƒå¼è®­ç»ƒæ¨¡å—
â”œâ”€â”€ task.py           # è®­ç»ƒä»»åŠ¡å®šä¹‰
â”œâ”€â”€ data.py           # æ•°æ®å¤„ç†
â”œâ”€â”€ arguments.py      # è®­ç»ƒå‚æ•°
â”œâ”€â”€ run_trainer.py    # è®­ç»ƒå¯åŠ¨è„šæœ¬
â”œâ”€â”€ inference/        # æ¨ç†æ¨¡å—
â””â”€â”€ lib/              # è®­ç»ƒåº“

## ğŸ›ï¸ æ™ºèƒ½åˆçº¦æ¶æ„

### æ ¸å¿ƒåˆçº¦ç³»ç»Ÿ

#### 1. InjectiveAiHub.sol - ä¸»åˆçº¦
**åŠŸèƒ½**: å¹³å°æ ¸å¿ƒç®¡ç†åˆçº¦ï¼Œå¤„ç†æä¾›è€…æ³¨å†Œã€èŠ‚ç‚¹éªŒè¯å’Œè´¨æŠ¼ç®¡ç†

**ä¸»è¦åŠŸèƒ½**:
- ğŸ” **æä¾›è€…æ³¨å†Œ**: ä½¿ç”¨INJè´¨æŠ¼æ³¨å†Œè®¡ç®—èµ„æºæä¾›è€…
- âœ… **èŠ‚ç‚¹éªŒè¯**: éªŒè¯è€…è§’è‰²éªŒè¯è®¡ç®—èŠ‚ç‚¹
- ğŸ’° **è´¨æŠ¼ç®¡ç†**: INJè´¨æŠ¼ã€å¢åŠ è´¨æŠ¼ã€å–å›è´¨æŠ¼
- âš¡ **æƒ©ç½šæœºåˆ¶**: å¯¹æ¶æ„è¡Œä¸ºè¿›è¡Œè´¨æŠ¼æƒ©ç½š
- ğŸ·ï¸ **ç™½åå•ç®¡ç†**: æä¾›è€…ç™½åå•å’Œé»‘åå•ç®¡ç†

```solidity
// æ ¸å¿ƒåŠŸèƒ½ç¤ºä¾‹
function registerProvider() external payable {
    uint256 stake = msg.value;
    require(stake >= stakeMinimum, "è´¨æŠ¼é‡‘é¢ä½äºæœ€ä½è¦æ±‚");
    // æ³¨å†Œé€»è¾‘...
}

function addComputeNode(address nodekey, string calldata specsURI, uint256 computeUnits, bytes memory signature) external {
    // æ·»åŠ è®¡ç®—èŠ‚ç‚¹é€»è¾‘...
}
```

#### 2. ComputeRegistry.sol - è®¡ç®—èµ„æºæ³¨å†Œè¡¨
**åŠŸèƒ½**: ç®¡ç†è®¡ç®—èµ„æºæä¾›è€…å’ŒèŠ‚ç‚¹ä¿¡æ¯

**ä¸»è¦åŠŸèƒ½**:
- ğŸ“‹ **æä¾›è€…ç®¡ç†**: æ³¨å†Œã€æ³¨é”€è®¡ç®—èµ„æºæä¾›è€…
- ğŸ–¥ï¸ **èŠ‚ç‚¹ç®¡ç†**: æ·»åŠ ã€ç§»é™¤ã€éªŒè¯è®¡ç®—èŠ‚ç‚¹
- ğŸ“Š **èµ„æºç»Ÿè®¡**: è·Ÿè¸ªæä¾›è€…çš„æ€»è®¡ç®—å•å…ƒ
- ğŸ” **çŠ¶æ€æŸ¥è¯¢**: æŸ¥è¯¢æä¾›è€…å’ŒèŠ‚ç‚¹çŠ¶æ€

#### 3. StakeManager.sol - è´¨æŠ¼ç®¡ç†å™¨
**åŠŸèƒ½**: å¤„ç†INJä»£å¸çš„è´¨æŠ¼ã€è§£è´¨æŠ¼å’Œæƒ©ç½š

**ä¸»è¦åŠŸèƒ½**:
- ğŸ’ **INJè´¨æŠ¼**: æ¥æ”¶å’Œç®¡ç†åŸç”ŸINJè´¨æŠ¼
- ğŸ”“ **è§£è´¨æŠ¼**: å¤„ç†è´¨æŠ¼è§£é”å’Œæå–
- âš–ï¸ **æƒ©ç½šæ‰§è¡Œ**: å¯¹è¿è§„è¡Œä¸ºæ‰§è¡Œè´¨æŠ¼æƒ©ç½š
- â° **è§£ç»‘æœŸç®¡ç†**: ç®¡ç†è´¨æŠ¼è§£ç»‘ç­‰å¾…æœŸ

#### 4. ComputePool.sol - è®¡ç®—æ± ç®¡ç†
**åŠŸèƒ½**: ç®¡ç†AIè®­ç»ƒä»»åŠ¡çš„è®¡ç®—æ± 

**ä¸»è¦åŠŸèƒ½**:
- ğŸ¯ **ä»»åŠ¡åˆ›å»º**: åˆ›å»ºAIè®­ç»ƒè®¡ç®—æ± 
- ğŸ‘¥ **å‚ä¸è€…ç®¡ç†**: ç®¡ç†è®¡ç®—æ± å‚ä¸è€…
- ğŸ“ˆ **è¿›åº¦è·Ÿè¸ª**: è·Ÿè¸ªè®­ç»ƒè¿›åº¦å’Œè´¡çŒ®
- ğŸ† **å¥–åŠ±åˆ†é…**: åŸºäºè´¡çŒ®åˆ†é…å¥–åŠ±

#### 5. DomainRegistry.sol - é¢†åŸŸæ³¨å†Œè¡¨
**åŠŸèƒ½**: ç®¡ç†ä¸åŒAIè®­ç»ƒé¢†åŸŸå’ŒéªŒè¯é€»è¾‘

**ä¸»è¦åŠŸèƒ½**:
- ğŸ·ï¸ **é¢†åŸŸåˆ›å»º**: åˆ›å»ºæ–°çš„AIè®­ç»ƒé¢†åŸŸ
- ğŸ”§ **éªŒè¯é€»è¾‘**: ç®¡ç†é¢†åŸŸç‰¹å®šçš„å·¥ä½œéªŒè¯
- ğŸ“ **å…ƒæ•°æ®ç®¡ç†**: å­˜å‚¨é¢†åŸŸæè¿°å’Œå‚æ•°

#### 6. RewardsDistributor.sol - å¥–åŠ±åˆ†é…å™¨
**åŠŸèƒ½**: ç®¡ç†åŸºäºè´¡çŒ®çš„INJå¥–åŠ±åˆ†é…

**ä¸»è¦åŠŸèƒ½**:
- ğŸ’° **å¥–åŠ±è®¡ç®—**: åŸºäºå·¥ä½œè´¡çŒ®è®¡ç®—å¥–åŠ±
- ğŸ“Š **åˆ†é…ç®¡ç†**: ç®¡ç†å¥–åŠ±åˆ†é…ç­–ç•¥
- ğŸ **å¥–åŠ±é¢†å–**: å¤„ç†å‚ä¸è€…å¥–åŠ±é¢†å–

### ğŸ” æƒé™å’Œè§’è‰²ç³»ç»Ÿ

```solidity
// è§’è‰²å®šä¹‰
bytes32 public constant FEDERATOR_ROLE = keccak256("FEDERATOR_ROLE");  // è”é‚¦è€…è§’è‰²
bytes32 public constant VALIDATOR_ROLE = keccak256("VALIDATOR_ROLE");  // éªŒè¯è€…è§’è‰²
bytes32 public constant DEFAULT_ADMIN_ROLE = 0x00;                    // ç®¡ç†å‘˜è§’è‰²
```

**è§’è‰²æƒé™**:
- ğŸ”‘ **ç®¡ç†å‘˜**: è®¾ç½®æ¨¡å—åœ°å€ã€ç®¡ç†ç³»ç»Ÿé…ç½®
- ğŸ‘‘ **è”é‚¦è€…**: åˆ›å»ºé¢†åŸŸã€è®¾ç½®è´¨æŠ¼æœ€ä½è¦æ±‚ã€ç®¡ç†éªŒè¯è€…
- âœ… **éªŒè¯è€…**: éªŒè¯èŠ‚ç‚¹ã€æ‰§è¡Œæƒ©ç½šã€ç®¡ç†ç™½åå•

### ğŸ’ INJè´¨æŠ¼æœºåˆ¶

#### è´¨æŠ¼è¦æ±‚
```solidity
function calculateMinimumStake(address provider, uint256 computeUnits) public view returns (uint256) {
    uint256 providerTotalCompute = computeRegistry.getProviderTotalCompute(provider);
    uint256 minStakePerComputeUnit = stakeManager.getStakeMinimum();
    uint256 requiredStake = (providerTotalCompute + computeUnits) * minStakePerComputeUnit;
    return requiredStake + minStakePerComputeUnit; // åŸºç¡€è´¨æŠ¼ + è®¡ç®—å•å…ƒè´¨æŠ¼
}
```

#### è´¨æŠ¼æµç¨‹
1. **æ³¨å†Œè´¨æŠ¼**: æä¾›è€…ä½¿ç”¨INJæ³¨å†Œå¹¶è´¨æŠ¼
2. **å¢åŠ è´¨æŠ¼**: æ ¹æ®éœ€è¦å¢åŠ æ›´å¤šè®¡ç®—å•å…ƒçš„è´¨æŠ¼
3. **è´¨æŠ¼éªŒè¯**: éªŒè¯è€…ç¡®è®¤è´¨æŠ¼æ»¡è¶³è¦æ±‚
4. **æƒ©ç½šæœºåˆ¶**: æ¶æ„è¡Œä¸ºå¯¼è‡´è´¨æŠ¼è¢«æƒ©ç½š
5. **å–å›è´¨æŠ¼**: éµå¾ªè§£ç»‘æœŸåå–å›è´¨æŠ¼

## ğŸ¦™ LlamaCore - åˆ†å¸ƒå¼AIè®­ç»ƒæ¨¡å—

### æ¨¡å—æ¦‚è¿°

LlamaCoreæ˜¯InjectiveAiHubçš„æ ¸å¿ƒAIè®­ç»ƒæ¨¡å—ï¼Œä¸“é—¨ç”¨äºLLaMA 2 7Bå¤§è¯­è¨€æ¨¡å‹çš„åˆ†å¸ƒå¼åä½œè®­ç»ƒã€‚è¯¥æ¨¡å—åŸºäºHivemindæ¡†æ¶å®ç°å»ä¸­å¿ƒåŒ–çš„è”é‚¦å­¦ä¹ ï¼Œæ”¯æŒå¤šèŠ‚ç‚¹åä½œè®­ç»ƒã€‚

### ğŸ¯ æ ¸å¿ƒç‰¹æ€§

- ğŸ¤– **LLaMA 2 7Bæ¨¡å‹**: æ”¯æŒMetaçš„LLaMA 2 7Bå‚æ•°å¤§è¯­è¨€æ¨¡å‹
- ğŸŒ **åˆ†å¸ƒå¼è®­ç»ƒ**: åŸºäºHivemindçš„å»ä¸­å¿ƒåŒ–åä½œè®­ç»ƒ
- ğŸ“Š **OpenWebTextæ•°æ®é›†**: ä½¿ç”¨é«˜è´¨é‡æ–‡æœ¬æ•°æ®è¿›è¡Œè®­ç»ƒ
- ğŸ” **éšç§ä¿æŠ¤**: éšè—èŠ‚ç‚¹IPå’Œèº«ä»½ä¿¡æ¯
- âš¡ **é«˜æ•ˆè®­ç»ƒ**: æ”¯æŒFP16æ··åˆç²¾åº¦è®­ç»ƒ
- ğŸ›ï¸ **çµæ´»é…ç½®**: å¯é…ç½®çš„è®­ç»ƒå‚æ•°å’Œç½‘ç»œè®¾ç½®

### ğŸ“ æ¨¡å—ç»“æ„
llamacore/
â”œâ”€â”€ task.py              # è®­ç»ƒä»»åŠ¡å®šä¹‰å’Œæ¨¡å‹é…ç½®
â”œâ”€â”€ data.py              # æ•°æ®åŠ è½½å’Œé¢„å¤„ç†
â”œâ”€â”€ arguments.py         # è®­ç»ƒå‚æ•°å’Œç½‘ç»œé…ç½®
â”œâ”€â”€ run_trainer.py       # ä¸»è®­ç»ƒè„šæœ¬
â”œâ”€â”€ run_aux_peer.py      # è¾…åŠ©èŠ‚ç‚¹è„šæœ¬
â”œâ”€â”€ callback.py          # è®­ç»ƒå›è°ƒå‡½æ•°
â”œâ”€â”€ utils.py             # å·¥å…·å‡½æ•°
â”œâ”€â”€ requirements.txt     # Pythonä¾èµ–
â”œâ”€â”€ inference/           # æ¨ç†æ¨¡å—
â”‚   â””â”€â”€ run_inference.py # æ–‡æœ¬ç”Ÿæˆæ¨ç†è„šæœ¬
â””â”€â”€ lib/                 # è®­ç»ƒåº“
â””â”€â”€ training/
â””â”€â”€ hf_trainer.py # Hugging Faceè®­ç»ƒå™¨é€‚é…

### ğŸš€ å¿«é€Ÿå¼€å§‹

#### ç¯å¢ƒè¦æ±‚

- **Python** >= 3.8
- **PyTorch** >= 1.12.0
- **CUDA** >= 11.6 (GPUè®­ç»ƒ)
- **Transformers** >= 4.21.0
- **Hivemind** >= 1.1.0

#### å®‰è£…ä¾èµ–

```bash
cd llamacore
pip install -r requirements.txt
```

#### Hugging Faceè®¤è¯

```bash
# è®¾ç½®Hugging Faceè®¿é—®ä»¤ç‰Œ
export HUGGINGFACE_TOKEN="your_token_here"

# æˆ–ä½¿ç”¨huggingface-cliç™»å½•
huggingface-cli login
```

#### å¯åŠ¨è®­ç»ƒ

```bash
# å¯åŠ¨ä¸»è®­ç»ƒèŠ‚ç‚¹
python run_trainer.py \
    --experiment_prefix "llama2-7b-training" \
    --per_device_train_batch_size 1 \
    --gradient_accumulation_steps 16 \
    --learning_rate 1e-5 \
    --fp16 \
    --total_steps 10000

# å¯åŠ¨è¾…åŠ©è®­ç»ƒèŠ‚ç‚¹
python run_aux_peer.py \
    --experiment_prefix "llama2-7b-training" \
    --host_maddrs "/ip4/127.0.0.1/tcp/0"
```

#### æ–‡æœ¬ç”Ÿæˆæ¨ç†

```bash
# åˆ›å»ºæç¤ºæ–‡ä»¶
echo "äººå·¥æ™ºèƒ½çš„æœªæ¥å‘å±•è¶‹åŠ¿æ˜¯" > prompts.txt
echo "åŒºå—é“¾æŠ€æœ¯åœ¨é‡‘èé¢†åŸŸçš„åº”ç”¨åŒ…æ‹¬" >> prompts.txt

# è¿è¡Œæ¨ç†
python inference/run_inference.py \
    --prompts prompts.txt \
    --output-dir ./outputs \
    --max-length 512 \
    --temperature 0.7
```

### âš™ï¸ é…ç½®è¯´æ˜

#### è®­ç»ƒå‚æ•°é…ç½®

```python
# arguments.py ä¸­çš„å…³é”®å‚æ•°
class TrainingArguments:
    per_device_train_batch_size: int = 1      # æ¯è®¾å¤‡æ‰¹æ¬¡å¤§å°
    gradient_accumulation_steps: int = 16     # æ¢¯åº¦ç´¯ç§¯æ­¥æ•°
    learning_rate: float = 1e-5               # å­¦ä¹ ç‡
    text_seq_length: int = 2048               # æ–‡æœ¬åºåˆ—é•¿åº¦
    total_steps: int = 10000                  # æ€»è®­ç»ƒæ­¥æ•°
    warmup_steps: int = 500                   # é¢„çƒ­æ­¥æ•°
    fp16: bool = True                         # æ··åˆç²¾åº¦è®­ç»ƒ
```

#### ç½‘ç»œé…ç½®

```python
# éšç§ä¿æŠ¤é…ç½®
class BasePeerArguments:
    host_maddrs: List[str] = ["/ip4/127.0.0.1/tcp/0"]  # åªç›‘å¬æœ¬åœ°
    announce_maddrs: List[str] = []                      # ä¸å…¬å¸ƒåœ°å€
    client_mode: bool = True                             # å®¢æˆ·ç«¯æ¨¡å¼
```

### ğŸ“Š è®­ç»ƒç›‘æ§

#### æ—¥å¿—è¾“å‡º

```bash
# è®­ç»ƒè¿‡ç¨‹ä¸­çš„å…³é”®æ—¥å¿—
[INFO] æ¨¡å‹åŠ è½½å®Œæˆ: LlamaForCausalLM
[INFO] æ•°æ®é›†åŠ è½½å®Œæˆ: openwebtext (æ ·æœ¬æ•°: 1000000)
[INFO] DHTç½‘ç»œè¿æ¥æˆåŠŸ
[INFO] å¼€å§‹åä½œè®­ç»ƒ...
[INFO] Step 100/10000, Loss: 2.45, LR: 1e-5
```

#### æ€§èƒ½æŒ‡æ ‡

- **è®­ç»ƒé€Ÿåº¦**: ~0.5 steps/sec (å•GPU)
- **å†…å­˜ä½¿ç”¨**: ~14GB VRAM (FP16)
- **ç½‘ç»œå¸¦å®½**: ~10MB/s (æ¢¯åº¦åŒæ­¥)
- **æ¨¡å‹å¤§å°**: ~13GB (7Bå‚æ•°)

### ğŸ”§ é«˜çº§é…ç½®

#### è‡ªå®šä¹‰æ•°æ®é›†

```python
# data.py ä¸­ä¿®æ”¹æ•°æ®é›†
def make_dataset(tokenizer, args):
    # æ›¿æ¢ä¸ºè‡ªå®šä¹‰æ•°æ®é›†
    dataset = load_dataset("your_custom_dataset")
    # ... æ•°æ®é¢„å¤„ç†é€»è¾‘
    return dataset
```

#### æ¨¡å‹å¾®è°ƒ

```python
# task.py ä¸­çš„æ¨¡å‹é…ç½®
class ModelWrapper:
    def __init__(self):
        self.model = LlamaForCausalLM.from_pretrained(
            "meta-llama/Llama-2-7b-hf",
            torch_dtype=torch.float16,
            device_map="auto"
        )
```

## ğŸš€ å®Œæ•´éƒ¨ç½²æŒ‡å—

### ç¯å¢ƒè¦æ±‚

- **Node.js** >= 18.0.0
- **pnpm** >= 8.0.0
- **Foundry** >= 0.2.0
- **Python** >= 3.8
- **Git**
- **Injectiveé’±åŒ…** (Keplr, Leapç­‰)

### 1. å…‹éš†å’Œåˆå§‹åŒ–é¡¹ç›®

```bash
# å…‹éš†ä»“åº“
git clone https://github.com/your-org/injectiveAiHub.git
cd injectiveAiHub

# å®‰è£…pnpm (å¦‚æœæœªå®‰è£…)
npm install -g pnpm
```

### 2. æ™ºèƒ½åˆçº¦éƒ¨ç½²

```bash
# è¿›å…¥åˆçº¦ç›®å½•
cd apps/inj_t

# å®‰è£…Foundryä¾èµ–
forge install

# ç¼–è¯‘åˆçº¦
forge build

# è¿è¡Œæµ‹è¯•
forge test

# éƒ¨ç½²åˆ°Injectiveæµ‹è¯•ç½‘
forge script script/Deploy.s.sol \
    --rpc-url $INJECTIVE_TESTNET_RPC \
    --private-key $PRIVATE_KEY \
    --broadcast

# éƒ¨ç½²åˆ°Injectiveä¸»ç½‘
forge script script/Deploy.s.sol \
    --rpc-url $INJECTIVE_MAINNET_RPC \
    --private-key $PRIVATE_KEY \
    --broadcast
```

### 3. å‰ç«¯åº”ç”¨éƒ¨ç½²

```bash
# è¿”å›é¡¹ç›®æ ¹ç›®å½•
cd ../..

# è¿›å…¥å‰ç«¯ç›®å½•
cd apps/frontend

# å®‰è£…ä¾èµ– (ä½¿ç”¨pnpm)
pnpm install

# é…ç½®ç¯å¢ƒå˜é‡
cp .env.example .env.local
# ç¼–è¾‘ .env.local æ–‡ä»¶ï¼Œé…ç½®ä»¥ä¸‹å˜é‡ï¼š
# NEXT_PUBLIC_INJECTIVE_NETWORK=testnet
# NEXT_PUBLIC_CONTRACT_ADDRESS=0x...
# NEXT_PUBLIC_WALLET_CONNECT_PROJECT_ID=your_project_id
```

#### ç¯å¢ƒå˜é‡é…ç½®

```bash
# .env.local ç¤ºä¾‹
NEXT_PUBLIC_INJECTIVE_NETWORK=testnet
NEXT_PUBLIC_CONTRACT_ADDRESS=0x1234567890abcdef...
NEXT_PUBLIC_WALLET_CONNECT_PROJECT_ID=your_wallet_connect_project_id
NEXT_PUBLIC_IPFS_GATEWAY=https://ipfs.io/ipfs/
NEXT_PUBLIC_API_BASE_URL=http://localhost:3000/api
```

#### å¯åŠ¨å¼€å‘æœåŠ¡å™¨

```bash
# å¯åŠ¨å‰ç«¯å¼€å‘æœåŠ¡å™¨
pnpm dev

# æˆ–è€…æŒ‡å®šç«¯å£
pnpm dev --port 3001

# æ„å»ºç”Ÿäº§ç‰ˆæœ¬
pnpm build

# å¯åŠ¨ç”Ÿäº§æœåŠ¡å™¨
pnpm start
```

#### å‰ç«¯åŠŸèƒ½ç‰¹æ€§

- ğŸ”— **é’±åŒ…è¿æ¥**: æ”¯æŒKeplrã€Leapç­‰Injectiveé’±åŒ…
- ğŸ’° **è´¨æŠ¼ç®¡ç†**: å¯è§†åŒ–è´¨æŠ¼ã€å¢åŠ è´¨æŠ¼ã€å–å›è´¨æŠ¼
- ğŸ–¥ï¸ **èŠ‚ç‚¹ç®¡ç†**: æ·»åŠ ã€æŸ¥çœ‹ã€ç®¡ç†è®¡ç®—èŠ‚ç‚¹
- ğŸ“Š **ä»ªè¡¨æ¿**: å®æ—¶æ˜¾ç¤ºç½‘ç»œçŠ¶æ€å’Œä¸ªäººè´¡çŒ®
- ğŸ¯ **ä»»åŠ¡åˆ›å»º**: åˆ›å»ºå’Œç®¡ç†AIè®­ç»ƒä»»åŠ¡
- ğŸ† **å¥–åŠ±æŸ¥çœ‹**: æŸ¥çœ‹å’Œé¢†å–è®­ç»ƒå¥–åŠ±

### 4. LlamaCore AIè®­ç»ƒæ¨¡å—éƒ¨ç½²

```bash
# è¿”å›é¡¹ç›®æ ¹ç›®å½•
cd ../..

# è¿›å…¥LlamaCoreç›®å½•
cd llamacore

# åˆ›å»ºPythonè™šæ‹Ÿç¯å¢ƒ
python -m venv venv
source venv/bin/activate  # Linux/Mac
# æˆ– venv\Scripts\activate  # Windows

# å®‰è£…Pythonä¾èµ–
pip install -r requirements.txt

# é…ç½®Hugging Faceè®¤è¯
export HUGGINGFACE_TOKEN="your_huggingface_token"
# æˆ–ä½¿ç”¨
huggingface-cli login
```

#### å¯åŠ¨AIè®­ç»ƒèŠ‚ç‚¹

```bash
# å¯åŠ¨ä¸»è®­ç»ƒèŠ‚ç‚¹
python run_trainer.py \
    --experiment_prefix "llama2-7b-training" \
    --per_device_train_batch_size 1 \
    --gradient_accumulation_steps 16 \
    --learning_rate 1e-5 \
    --fp16 \
    --total_steps 10000 \
    --warmup_steps 500

# åœ¨å¦ä¸€ä¸ªç»ˆç«¯å¯åŠ¨è¾…åŠ©èŠ‚ç‚¹
python run_aux_peer.py \
    --experiment_prefix "llama2-7b-training" \
    --host_maddrs "/ip4/127.0.0.1/tcp/0"
```

#### AIæ¨ç†æœåŠ¡

```bash
# åˆ›å»ºæ¨ç†æç¤ºæ–‡ä»¶
echo "äººå·¥æ™ºèƒ½çš„æœªæ¥å‘å±•æ–¹å‘åŒ…æ‹¬" > prompts.txt
echo "åŒºå—é“¾æŠ€æœ¯çš„ä¸»è¦ä¼˜åŠ¿æ˜¯" >> prompts.txt
echo "åˆ†å¸ƒå¼æœºå™¨å­¦ä¹ çš„æŒ‘æˆ˜æœ‰" >> prompts.txt

# è¿è¡Œæ–‡æœ¬ç”Ÿæˆæ¨ç†
python inference/run_inference.py \
    --prompts prompts.txt \
    --output-dir ./inference_outputs \
    --max-length 512 \
    --temperature 0.7 \
    --top-p 0.9 \
    --num-samples 3
```

### 5. å®Œæ•´ç³»ç»Ÿå¯åŠ¨

#### å¼€å‘ç¯å¢ƒå¯åŠ¨è„šæœ¬

```bash
#!/bin/bash
# start_dev.sh

echo "ğŸš€ å¯åŠ¨InjectiveAiHubå¼€å‘ç¯å¢ƒ..."

# å¯åŠ¨å‰ç«¯å¼€å‘æœåŠ¡å™¨
echo "ğŸ“± å¯åŠ¨å‰ç«¯æœåŠ¡å™¨..."
cd apps/frontend
pnpm dev --port 3000 &
FRONTEND_PID=$!

# å¯åŠ¨LlamaCoreè®­ç»ƒèŠ‚ç‚¹
echo "ğŸ¤– å¯åŠ¨AIè®­ç»ƒèŠ‚ç‚¹..."
cd ../../llamacore
source venv/bin/activate
python run_trainer.py \
    --experiment_prefix "dev-llama2-training" \
    --per_device_train_batch_size 1 \
    --gradient_accumulation_steps 8 \
    --learning_rate 1e-5 \
    --fp16 \
    --total_steps 1000 &
TRAINER_PID=$!

echo "âœ… æ‰€æœ‰æœåŠ¡å·²å¯åŠ¨"
echo "ğŸ“± å‰ç«¯åœ°å€: http://localhost:3000"
echo "ğŸ¤– AIè®­ç»ƒèŠ‚ç‚¹PID: $TRAINER_PID"
echo "ğŸ“± å‰ç«¯æœåŠ¡PID: $FRONTEND_PID"

# ç­‰å¾…ç”¨æˆ·è¾“å…¥ä»¥åœæ­¢æœåŠ¡
read -p "æŒ‰Enteré”®åœæ­¢æ‰€æœ‰æœåŠ¡..."

echo "ğŸ›‘ åœæ­¢æ‰€æœ‰æœåŠ¡..."
kill $FRONTEND_PID $TRAINER_PID
echo "âœ… æ‰€æœ‰æœåŠ¡å·²åœæ­¢"
```

#### ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²

```bash
# æ„å»ºå‰ç«¯ç”Ÿäº§ç‰ˆæœ¬
cd apps/frontend
pnpm build

# ä½¿ç”¨PM2ç®¡ç†Node.jsè¿›ç¨‹
npm install -g pm2
pm2 start ecosystem.config.js

# ä½¿ç”¨systemdç®¡ç†LlamaCoreè®­ç»ƒæœåŠ¡
sudo cp llamacore.service /etc/systemd/system/
sudo systemctl enable llamacore
sudo systemctl start llamacore
```

## ğŸ§ª æ™ºèƒ½åˆçº¦æµ‹è¯•

### æµ‹è¯•å¥—ä»¶

```bash
# è¿›å…¥åˆçº¦ç›®å½•
cd apps/inj_t

# è¿è¡Œæ‰€æœ‰æµ‹è¯•
forge test

# è¿è¡Œç‰¹å®šæµ‹è¯•æ–‡ä»¶
forge test --match-path test/InjectiveAiHub.t.sol

# è¿è¡Œç‰¹å®šæµ‹è¯•å‡½æ•°
forge test --match-test testRegisterProvider

# ç”Ÿæˆæµ‹è¯•è¦†ç›–ç‡æŠ¥å‘Š
forge coverage

# è¯¦ç»†æµ‹è¯•è¾“å‡º
forge test -vvv
```

### æµ‹è¯•ç”¨ä¾‹è¦†ç›–

- âœ… **æä¾›è€…æ³¨å†Œå’Œè´¨æŠ¼**
- âœ… **è®¡ç®—èŠ‚ç‚¹æ·»åŠ å’ŒéªŒè¯**
- âœ… **è´¨æŠ¼å¢åŠ å’Œå–å›**
- âœ… **æƒ©ç½šæœºåˆ¶æ‰§è¡Œ**
- âœ… **æƒé™å’Œè§’è‰²ç®¡ç†**
- âœ… **å¥–åŠ±åˆ†é…é€»è¾‘**
- âœ… **è¾¹ç•Œæ¡ä»¶å’Œé”™è¯¯å¤„ç†**

## ğŸ“Š åˆçº¦äº¤äº’ç¤ºä¾‹

### 1. æ³¨å†Œä¸ºè®¡ç®—æä¾›è€…

```javascript
// ä½¿ç”¨Web3.jsæˆ–ethers.js
const tx = await injectiveAiHub.registerProvider({
    value: ethers.utils.parseEther("100") // è´¨æŠ¼100 INJ
});
```

### 2. æ·»åŠ è®¡ç®—èŠ‚ç‚¹

```javascript
const signature = await signNodeKey(provider, nodekey);
const tx = await injectiveAiHub.addComputeNode(
    nodekey,
    "ipfs://QmSpecsURI",
    10, // 10ä¸ªè®¡ç®—å•å…ƒ
    signature
);
```

### 3. åˆ›å»ºAIè®­ç»ƒé¢†åŸŸ

```javascript
const tx = await injectiveAiHub.createDomain(
    "å›¾åƒè¯†åˆ«",
    validationLogicAddress,
    "ipfs://QmDomainURI"
);
```

## ğŸ”§ é…ç½®å’Œéƒ¨ç½²

### ç½‘ç»œé…ç½®

```toml
# foundry.toml
[profile.default]
src = "src"
out = "out"
libs = ["lib"]

[rpc_endpoints]
injective_testnet = "https://testnet.sentry.tm.injective.network:443"
injective_mainnet = "https://sentry.tm.injective.network:443"
```

### éƒ¨ç½²è„šæœ¬

```solidity
// script/Deploy.s.sol
contract DeployScript is Script {
    function run() external {
        vm.startBroadcast();
        
        // éƒ¨ç½²æ ¸å¿ƒåˆçº¦
        InjectiveAiHub hub = new InjectiveAiHub(federator, validator);
        ComputeRegistry registry = new ComputeRegistry();
        StakeManager stakeManager = new StakeManager();
        
        // è®¾ç½®åˆçº¦åœ°å€
        hub.setModuleAddresses(
            address(registry),
            address(domainRegistry),
            address(stakeManager),
            address(computePool)
        );
        
        vm.stopBroadcast();
    }
}
```

## ğŸ“ˆ ç»æµæ¨¡å‹

### INJä»£å¸ç”¨é€”

1. **è´¨æŠ¼ä¿è¯é‡‘**: æä¾›è€…éœ€è¦è´¨æŠ¼INJä½œä¸ºæœåŠ¡ä¿è¯
2. **ç½‘ç»œè´¹ç”¨**: æ”¯ä»˜äº¤æ˜“å’Œè®¡ç®—è´¹ç”¨
3. **å¥–åŠ±åˆ†é…**: åŸºäºè´¡çŒ®è·å¾—INJå¥–åŠ±
4. **æ²»ç†æŠ•ç¥¨**: ä½¿ç”¨è´¨æŠ¼çš„INJå‚ä¸å¹³å°æ²»ç†

### å¥–åŠ±æœºåˆ¶

- ğŸ“Š **å·¥ä½œè´¡çŒ®å¥–åŠ±**: åŸºäºæäº¤çš„æœ‰æ•ˆå·¥ä½œé‡
- â° **åœ¨çº¿æ—¶é—´å¥–åŠ±**: åŸºäºèŠ‚ç‚¹åœ¨çº¿æ—¶é—´
- ğŸ¯ **è´¨é‡å¥–åŠ±**: åŸºäºå·¥ä½œè´¨é‡è¯„ä¼°
- ğŸ† **é•¿æœŸæ¿€åŠ±**: é•¿æœŸå‚ä¸è€…è·å¾—é¢å¤–å¥–åŠ±

## ğŸ›¡ï¸ å®‰å…¨ç‰¹æ€§

### æ™ºèƒ½åˆçº¦å®‰å…¨

- ğŸ” **è®¿é—®æ§åˆ¶**: åŸºäºè§’è‰²çš„æƒé™ç®¡ç†
- ğŸ›¡ï¸ **é‡å…¥ä¿æŠ¤**: é˜²æ­¢é‡å…¥æ”»å‡»
- âœ… **è¾“å…¥éªŒè¯**: ä¸¥æ ¼çš„å‚æ•°éªŒè¯
- ğŸ” **äº‹ä»¶æ—¥å¿—**: å®Œæ•´çš„æ“ä½œå®¡è®¡æ—¥å¿—

### ç»æµå®‰å…¨

- ğŸ’ **è´¨æŠ¼æœºåˆ¶**: ç»æµæ¿€åŠ±ç¡®ä¿è¯šå®è¡Œä¸º
- âš–ï¸ **æƒ©ç½šæœºåˆ¶**: å¯¹æ¶æ„è¡Œä¸ºè¿›è¡Œç»æµæƒ©ç½š
- ğŸ• **è§£ç»‘æœŸ**: é˜²æ­¢å¿«é€Ÿé€€å‡ºæ”»å‡»
- ğŸ“Š **åŠ¨æ€è°ƒæ•´**: æ ¹æ®ç½‘ç»œçŠ¶å†µè°ƒæ•´å‚æ•°

### AIè®­ç»ƒå®‰å…¨

- ğŸ” **éšç§ä¿æŠ¤**: è”é‚¦å­¦ä¹ ä¿æŠ¤æ•°æ®éšç§
- ğŸ›¡ï¸ **æ¨¡å‹éªŒè¯**: é˜²æ­¢æ¶æ„æ¨¡å‹æ›´æ–°
- ğŸ” **æ¢¯åº¦å®¡è®¡**: æ£€æµ‹å¼‚å¸¸æ¢¯åº¦æäº¤
- âš¡ **æ‹œå åº­å®¹é”™**: å®¹å¿éƒ¨åˆ†æ¶æ„èŠ‚ç‚¹

## ğŸ¤ è´¡çŒ®æŒ‡å—

### å¼€å‘æµç¨‹

1. **Forkä»“åº“**
2. **åˆ›å»ºåŠŸèƒ½åˆ†æ”¯**
```bash
git checkout -b feature/new-feature
```
3. **ç¼–å†™ä»£ç å’Œæµ‹è¯•**
4. **è¿è¡Œæµ‹è¯•å¥—ä»¶**
```bash
# åˆçº¦æµ‹è¯•
cd apps/inj_t && forge test

# å‰ç«¯æµ‹è¯•
cd apps/frontend && pnpm test

# AIæ¨¡å—æµ‹è¯•
cd llamacore && python -m pytest
```
5. **æäº¤æ›´æ”¹**
```bash
git commit -m "feat: æ·»åŠ æ–°åŠŸèƒ½"
```
6. **åˆ›å»ºPull Request**

### ä»£ç è§„èŒƒ

- ğŸ“ **Solidityé£æ ¼**: éµå¾ªSolidityå®˜æ–¹é£æ ¼æŒ‡å—
- ğŸ§ª **æµ‹è¯•è¦†ç›–**: æ–°åŠŸèƒ½å¿…é¡»åŒ…å«æµ‹è¯•
- ğŸ“š **æ–‡æ¡£æ›´æ–°**: æ›´æ–°ç›¸å…³æ–‡æ¡£
- ğŸ” **ä»£ç å®¡æŸ¥**: æ‰€æœ‰PRéœ€è¦ä»£ç å®¡æŸ¥
- ğŸ **Pythoné£æ ¼**: éµå¾ªPEP 8ä»£ç è§„èŒƒ
- âš›ï¸ **Reacté£æ ¼**: éµå¾ªReactå’ŒTypeScriptæœ€ä½³å®è·µ

## ğŸ“š æ–‡æ¡£å’Œèµ„æº

### æŠ€æœ¯æ–‡æ¡£

- [æ™ºèƒ½åˆçº¦APIæ–‡æ¡£](./docs/contracts/)
- [å‰ç«¯é›†æˆæŒ‡å—](./docs/frontend/)
- [LlamaCoreè®­ç»ƒæŒ‡å—](./docs/llamacore/)
- [éƒ¨ç½²æŒ‡å—](./docs/deployment/)
- [å®‰å…¨æœ€ä½³å®è·µ](./docs/security/)

### ç¤¾åŒºèµ„æº

- ğŸ› **é—®é¢˜æŠ¥å‘Š**: [GitHub Issues](https://github.com/your-org/injectiveAiHub/issues)
- ğŸ’¬ **è®¨è®ºåŒº**: [GitHub Discussions](https://github.com/your-org/injectiveAiHub/discussions)
- ğŸ“§ **é‚®ä»¶æ”¯æŒ**: support@injectiveaihub.ai
- ğŸ’­ **Discordç¤¾åŒº**: [åŠ å…¥æˆ‘ä»¬](https://discord.gg/injectiveaihub)

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨MITè®¸å¯è¯ - æŸ¥çœ‹[LICENSE](LICENSE)æ–‡ä»¶äº†è§£è¯¦æƒ…ã€‚

## ğŸ™ è‡´è°¢

- [Injective Labs](https://injective.com/) - æä¾›åŒºå—é“¾åŸºç¡€è®¾æ–½
- [Foundry](https://getfoundry.sh/) - æ™ºèƒ½åˆçº¦å¼€å‘å·¥å…·
- [OpenZeppelin](https://openzeppelin.com/) - å®‰å…¨çš„æ™ºèƒ½åˆçº¦åº“
- [Meta AI](https://ai.meta.com/) - LLaMA 2æ¨¡å‹
- [Hivemind](https://github.com/learning-at-home/hivemind) - åˆ†å¸ƒå¼è®­ç»ƒæ¡†æ¶
- [Hugging Face](https://huggingface.co/) - Transformersåº“å’Œæ¨¡å‹æ‰˜ç®¡
- å¼€æºç¤¾åŒºçš„æ‰€æœ‰è´¡çŒ®è€…

---

<div align="center">
<p>ğŸš€ ç”±InjectiveAiHubå›¢é˜Ÿç”¨â¤ï¸æ„å»º</p>
<p>ğŸŒŸ é€šè¿‡åŒºå—é“¾æŠ€æœ¯èµ‹èƒ½åä½œå¼AI</p>
<p>ğŸ¦™ è®©AIè®­ç»ƒæ›´åŠ æ°‘ä¸»åŒ–å’Œå»ä¸­å¿ƒåŒ–</p>
</div>